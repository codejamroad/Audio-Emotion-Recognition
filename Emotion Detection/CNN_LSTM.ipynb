{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "CNN-LSTM.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "y9FCn5K74tQo",
        "outputId": "1b31ad1b-de87-46b7-dd33-3e91fc97ed52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import pickle\n",
        "import itertools\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "### Graph imports ###\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "### Audio import ###\n",
        "import librosa\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "\n",
        "### Plot imports ###\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "### Time Distributed ConvNet imports ###\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "### Warning ###\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8uBbyLX-4tQt"
      },
      "source": [
        "# Audio file path and names\n",
        "RAV = '/content/drive/My Drive/audio_speech_actors_01-24/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMC9LvYDBnmR"
      },
      "source": [
        "TESS = \"/content/drive/My Drive/TESS Toronto emotional speech set data/TESS Toronto emotional speech set data/\"\n",
        "\n",
        "SAVEEJE = \"/content/drive/My Drive/AudioData/AudioData/JE/\"\n",
        "SAVEEDC = \"/content/drive/My Drive/AudioData/AudioData/DC/\"\n",
        "SAVEEJK = \"/content/drive/My Drive/AudioData/AudioData/JK/\"\n",
        "SAVEEKL = \"/content/drive/My Drive/AudioData/AudioData/KL/\"\n",
        "CREMA = \"/content/drive/My Drive/AudioWAV/\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTWbgUmjzcnJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GZftANdr4tQx"
      },
      "source": [
        "dic  =  {1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}\n",
        "dic  =  {1:'male_neutral', 2:'male_calm', 3:'male_happy', 4:'male_sad', 5:'male_angry', 6:'male_fear', 7:'male_disgust', 8:'male_surprise',9:'female_neutral', 10:'female_calm', 11:'female_happy', 12:'female_sad', 13:'female_angry', 14:'female_fear', 15:'female_disgust', 16:'female_surprise'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UjS9vgAz4tQ1"
      },
      "source": [
        "# dir_list = os.listdir(RAV)\n",
        "# dir_list.sort()\n",
        "\n",
        "# emotion = []\n",
        "# path = []\n",
        "# for i in dir_list:\n",
        "#     fname = os.listdir(RAV + i)\n",
        "#     for f in fname:\n",
        "#         part = f.split('.')[0].split('-')\n",
        "#         emotion.append(int(part[2]))\n",
        "#         path.append(RAV + i + '/' + f)\n",
        "\n",
        "# RAV_df = pd.DataFrame() \n",
        "# RAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC-khJjvoxtv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad_P6zpPCMkG",
        "outputId": "17653284-b723-40ac-8922-0d0aa8c95ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "dir_list = os.listdir(RAV)\n",
        "dir_list.sort()\n",
        "\n",
        "emotion = []\n",
        "gender = []\n",
        "path = []\n",
        "for i in dir_list:\n",
        "    fname = os.listdir(RAV + i)\n",
        "    for f in fname:\n",
        "        part = f.split('.')[0].split('-')\n",
        "        emotion.append(int(part[2]))\n",
        "        temp = int(part[6])\n",
        "        if temp%2 == 0:\n",
        "            temp = \"female\"\n",
        "        else:\n",
        "            temp = \"male\"\n",
        "        gender.append(temp)\n",
        "        path.append(RAV + i + '/' + f)\n",
        "\n",
        "        \n",
        "RAV_df = pd.DataFrame(emotion)\n",
        "RAV_df = RAV_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
        "RAV_df = pd.concat([pd.DataFrame(gender),RAV_df],axis=1)\n",
        "RAV_df.columns = ['gender','emotion']\n",
        "RAV_df['labels'] =RAV_df.gender + '_' + RAV_df.emotion\n",
        "RAV_df['source'] = 'RAVDESS'  \n",
        "RAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
        "RAV_df = RAV_df.drop(['gender', 'emotion'], axis=1)\n",
        "RAV_df.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cf5c39db4c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdir_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdir_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0memotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/audio_speech_actors_01-24/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zc9V7tJCMhx"
      },
      "source": [
        "# Run one example \n",
        "dir_list = os.listdir(SAVEEJE)\n",
        "dir_list[0:5]\n",
        "# parse the filename to get the emotions\n",
        "emotion=[]\n",
        "path = []\n",
        "for i in dir_list:\n",
        "    if i[-8:-6]=='a':\n",
        "        emotion.append('male_angry')\n",
        "    elif i[-8:-6]=='d':\n",
        "        emotion.append('male_disgust')\n",
        "    elif i[-8:-6]=='f':\n",
        "        emotion.append('male_fear')\n",
        "    elif i[-8:-6]=='h':\n",
        "        emotion.append('male_happy')\n",
        "    elif i[-8:-6]=='n':\n",
        "        emotion.append('male_neutral')\n",
        "    elif i[-8:-6]=='sa':\n",
        "        emotion.append('male_sad')\n",
        "    elif i[-8:-6]=='su':\n",
        "        emotion.append('male_surprise')\n",
        "    else:\n",
        "        emotion.append('male_error') \n",
        "    path.append(SAVEEJE + i)\n",
        "    \n",
        "# Now check out the label count distribution \n",
        "SAVEE_dfje = pd.DataFrame(emotion, columns = ['labels'])\n",
        "SAVEE_dfje['source'] = 'SAVEEJE'\n",
        "SAVEE_dfje = pd.concat([SAVEE_dfje, pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
        "SAVEE_dfje.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F16uO-GCqFWm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utukj70wd0V2"
      },
      "source": [
        "# parse the filename to get the emotions\n",
        "dir_list = os.listdir(SAVEEDC)\n",
        "emotion=[]\n",
        "path = []\n",
        "for i in dir_list:\n",
        "    if i[-8:-6]=='a':\n",
        "        emotion.append('male_angry')\n",
        "    elif i[-8:-6]=='d':\n",
        "        emotion.append('male_disgust')\n",
        "    elif i[-8:-6]=='f':\n",
        "        emotion.append('male_fear')\n",
        "    elif i[-8:-6]=='h':\n",
        "        emotion.append('male_happy')\n",
        "    elif i[-8:-6]=='n':\n",
        "        emotion.append('male_neutral')\n",
        "    elif i[-8:-6]=='sa':\n",
        "        emotion.append('male_sad')\n",
        "    elif i[-8:-6]=='su':\n",
        "        emotion.append('male_surprise')\n",
        "    else:\n",
        "        emotion.append('male_error') \n",
        "    path.append(SAVEEDC + i)\n",
        "    \n",
        "# Now check out the label count distribution \n",
        "SAVEE_dfdc = pd.DataFrame(emotion, columns = ['labels'])\n",
        "SAVEE_dfdc['source'] = 'SAVEEDC'\n",
        "SAVEE_dfdc = pd.concat([SAVEE_dfdc, pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
        "SAVEE_dfdc.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zClaG5Yd0eL"
      },
      "source": [
        "# parse the filename to get the emotions\n",
        "dir_list = os.listdir(SAVEEJK)\n",
        "emotion=[]\n",
        "path = []\n",
        "for i in dir_list:\n",
        "    if i[-8:-6]=='a':\n",
        "        emotion.append('male_angry')\n",
        "    elif i[-8:-6]=='d':\n",
        "        emotion.append('male_disgust')\n",
        "    elif i[-8:-6]=='f':\n",
        "        emotion.append('male_fear')\n",
        "    elif i[-8:-6]=='h':\n",
        "        emotion.append('male_happy')\n",
        "    elif i[-8:-6]=='n':\n",
        "        emotion.append('male_neutral')\n",
        "    elif i[-8:-6]=='sa':\n",
        "        emotion.append('male_sad')\n",
        "    elif i[-8:-6]=='su':\n",
        "        emotion.append('male_surprise')\n",
        "    else:\n",
        "        emotion.append('male_error') \n",
        "    path.append(SAVEEJK + i)\n",
        "    \n",
        "# Now check out the label count distribution \n",
        "SAVEE_dfjk = pd.DataFrame(emotion, columns = ['labels'])\n",
        "SAVEE_dfjk['source'] = 'SAVEEJK'\n",
        "SAVEE_dfjk = pd.concat([SAVEE_dfjk, pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
        "SAVEE_dfjk.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhJiy6Fod0to"
      },
      "source": [
        "# parse the filename to get the emotions\n",
        "dir_list = os.listdir(SAVEEKL)\n",
        "emotion=[]\n",
        "path = []\n",
        "for i in dir_list:\n",
        "    if i[-8:-6]=='a':\n",
        "        emotion.append('male_angry')\n",
        "    elif i[-8:-6]=='d':\n",
        "        emotion.append('male_disgust')\n",
        "    elif i[-8:-6]=='f':\n",
        "        emotion.append('male_fear')\n",
        "    elif i[-8:-6]=='h':\n",
        "        emotion.append('male_happy')\n",
        "    elif i[-8:-6]=='n':\n",
        "        emotion.append('male_neutral')\n",
        "    elif i[-8:-6]=='sa':\n",
        "        emotion.append('male_sad')\n",
        "    elif i[-8:-6]=='su':\n",
        "        emotion.append('male_surprise')\n",
        "    else:\n",
        "        emotion.append('male_error') \n",
        "    path.append(SAVEEKL + i)\n",
        "    \n",
        "# Now check out the label count distribution \n",
        "SAVEE_dfkl = pd.DataFrame(emotion, columns = ['labels'])\n",
        "SAVEE_dfkl['source'] = 'SAVEEKL'\n",
        "SAVEE_dfkl = pd.concat([SAVEE_dfkl, pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
        "SAVEE_dfkl.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiIQtVWwDNG_"
      },
      "source": [
        "dir_list = os.listdir(TESS)\n",
        "dir_list.sort()\n",
        "dir_list\n",
        "path = []\n",
        "emotion = []\n",
        "\n",
        "for i in dir_list:\n",
        "    fname = os.listdir(TESS + i)\n",
        "    for f in fname:\n",
        "        if i == 'OAF_angry' or i == 'YAF_angry':\n",
        "            emotion.append('female_angry')\n",
        "        elif i == 'OAF_disgust' or i == 'YAF_disgust':\n",
        "            emotion.append('female_disgust')\n",
        "        elif i == 'OAF_Fear' or i == 'YAF_fear':\n",
        "            emotion.append('female_fear')\n",
        "        elif i == 'OAF_happy' or i == 'YAF_happy':\n",
        "            emotion.append('female_happy')\n",
        "        elif i == 'OAF_neutral' or i == 'YAF_neutral':\n",
        "            emotion.append('female_neutral')                                \n",
        "        elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n",
        "            emotion.append('female_surprise')               \n",
        "        elif i == 'OAF_Sad' or i == 'YAF_sad':\n",
        "            emotion.append('female_sad')\n",
        "        else:\n",
        "            emotion.append('Unknown')\n",
        "        path.append(TESS + i + \"/\" + f)\n",
        "\n",
        "TESS_df = pd.DataFrame(emotion, columns = ['labels'])\n",
        "TESS_df['source'] = 'TESS'\n",
        "TESS_df = pd.concat([TESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
        "TESS_df.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpQBwybwqFZZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFl3LhV7fmx3"
      },
      "source": [
        "dir_list = os.listdir(CREMA)\n",
        "gender = []\n",
        "emotion = []\n",
        "path = []\n",
        "female = [1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,1021,1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,\n",
        "          1052,1053,1054,1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,1076,1078,1079,1082,1084,1089,1091]\n",
        "\n",
        "for i in dir_list: \n",
        "    part = i.split('_')\n",
        "    if int(part[0]) in female:\n",
        "        temp = 'female'\n",
        "    else:\n",
        "        temp = 'male'\n",
        "    gender.append(temp)\n",
        "    if part[2] == 'SAD' and temp == 'male':\n",
        "        emotion.append('male_sad')\n",
        "    elif part[2] == 'ANG' and temp == 'male':\n",
        "        emotion.append('male_angry')\n",
        "    elif part[2] == 'DIS' and temp == 'male':\n",
        "        emotion.append('male_disgust')\n",
        "    elif part[2] == 'FEA' and temp == 'male':\n",
        "        emotion.append('male_fear')\n",
        "    elif part[2] == 'HAP' and temp == 'male':\n",
        "        emotion.append('male_happy')\n",
        "    elif part[2] == 'NEU' and temp == 'male':\n",
        "        emotion.append('male_neutral')\n",
        "    elif part[2] == 'SAD' and temp == 'female':\n",
        "        emotion.append('female_sad')\n",
        "    elif part[2] == 'ANG' and temp == 'female':\n",
        "        emotion.append('female_angry')\n",
        "    elif part[2] == 'DIS' and temp == 'female':\n",
        "        emotion.append('female_disgust')\n",
        "    elif part[2] == 'FEA' and temp == 'female':\n",
        "        emotion.append('female_fear')\n",
        "    elif part[2] == 'HAP' and temp == 'female':\n",
        "        emotion.append('female_happy')\n",
        "    elif part[2] == 'NEU' and temp == 'female':\n",
        "        emotion.append('female_neutral')\n",
        "    else:\n",
        "        emotion.append('Unknown')\n",
        "    path.append(CREMA + i)\n",
        "    \n",
        "CREMA_df = pd.DataFrame(emotion, columns = ['labels'])\n",
        "CREMA_df['source'] = 'CREMA'\n",
        "CREMA_df = pd.concat([CREMA_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
        "CREMA_df.labels.value_counts()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oWwrx08qFb4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI-b4LB8qFeS"
      },
      "source": [
        "RAV_df  = pd.DataFrame()\n",
        "RAV_df = pd.concat([SAVEE_dfje,SAVEE_dfdc,SAVEE_dfjk,SAVEE_dfkl, RAV_df, TESS_df, CREMA_df],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SkrCoLMMq1VX"
      },
      "source": [
        "# dir_list = os.listdir(RAV)\n",
        "# dir_list.sort()\n",
        "\n",
        "# emotion = []\n",
        "# path = []\n",
        "# for i in dir_list:\n",
        "#     fname = os.listdir(RAV + i)\n",
        "#     for f in fname:\n",
        "#         part = f.split('.')[0].split('-')\n",
        "#         emotion.append(int(part[2]))\n",
        "#         path.append(RAV + i + '/' + f)\n",
        "\n",
        "# RAV_df = pd.DataFrame() \n",
        "# RAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDX9F_I254PR"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IB2JI9xk4tQ3"
      },
      "source": [
        "RAV_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2kUVkgrsMMs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbcKgrrysMPc"
      },
      "source": [
        "RAV_df.path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Kd3CtrpA4tQ7"
      },
      "source": [
        "signal = []\n",
        "\n",
        "# Sample rate (16.0 kHz)\n",
        "sample_rate = 16000     \n",
        "\n",
        "# Max pad lenght (3.0 sec)\n",
        "max_pad_len = 49100\n",
        "\n",
        "for index,path in enumerate(RAV_df.path):\n",
        "    X, sample_rate = librosa.load(path\n",
        "                                  ,duration=3\n",
        "                                  ,offset=0.5\n",
        "                                 )\n",
        "    sample_rate = np.array(sample_rate)\n",
        "    \n",
        "    y = zscore(X)\n",
        "        \n",
        "    # Padding or truncated signal \n",
        "    if len(y) < max_pad_len:    \n",
        "        y_padded = np.zeros(max_pad_len)\n",
        "        y_padded[:len(y)] = y\n",
        "        y = y_padded\n",
        "    elif len(y) > max_pad_len:\n",
        "        y = np.asarray(y[:max_pad_len])\n",
        "\n",
        "    # Add to signal list\n",
        "    signal.append(y)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7zrjnAN54tQ-"
      },
      "source": [
        "labels = np.asarray(emotion).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8fw7Jgcb4tRB"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8p_E0RCR4tRE"
      },
      "source": [
        "np.unique(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qGMrNC4U4tRG"
      },
      "source": [
        "def noisy_signal(signal, snr_low=15, snr_high=30, nb_augmented=2):\n",
        "    \n",
        "    # Signal length\n",
        "    signal_len = len(signal)\n",
        "\n",
        "    # Generate White noise\n",
        "    noise = np.random.normal(size=(nb_augmented, signal_len))\n",
        "    \n",
        "    # Compute signal and noise power\n",
        "    s_power = np.sum((signal / (2.0 ** 15)) ** 2) / signal_len\n",
        "    n_power = np.sum((noise / (2.0 ** 15)) ** 2, axis=1) / signal_len\n",
        "    \n",
        "    # Random SNR: Uniform [15, 30]\n",
        "    snr = np.random.randint(snr_low, snr_high)\n",
        "    \n",
        "    # Compute K coeff for each noise\n",
        "    K = np.sqrt((s_power / n_power) * 10 ** (- snr / 10))\n",
        "    K = np.ones((signal_len, nb_augmented)) * K\n",
        "    \n",
        "    # Generate noisy signal\n",
        "    return signal + K.T * noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "K_frYox84tRJ"
      },
      "source": [
        "print(\"Data Augmentation: START\")\n",
        "augmented_signal = list(map(noisy_signal, signal))\n",
        "print(\"Data Augmentation: END!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "q4eu9uby4tRL"
      },
      "source": [
        "def mel_spectrogram(y, sr=16000, n_fft=512, win_length=256, hop_length=128, window='hamming', n_mels=128, fmax=4000):\n",
        "    \n",
        "    # Compute spectogram\n",
        "    mel_spect = np.abs(librosa.stft(y, n_fft=n_fft, window=window, win_length=win_length, hop_length=hop_length)) ** 2\n",
        "    \n",
        "    # Compute mel spectrogram\n",
        "    mel_spect = librosa.feature.melspectrogram(S=mel_spect, sr=sr, n_mels=n_mels, fmax=fmax)\n",
        "    \n",
        "    # Compute log-mel spectrogram\n",
        "    mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
        "    \n",
        "    return mel_spect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SckQjDEf4tRO"
      },
      "source": [
        "mel_spect = np.asarray(list(map(mel_spectrogram, signal)))\n",
        "augmented_mel_spect = [np.asarray(list(map(mel_spectrogram, augmented_signal[i]))) for i in range(len(augmented_signal))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jsNVk-824tRQ"
      },
      "source": [
        "MEL_SPECT_train, MEL_SPECT_test, AUG_MEL_SPECT_train, AUG_MEL_SPECT_test, label_train, label_test = train_test_split(mel_spect, augmented_mel_spect,labels, test_size=0.2,random_state=1)\n",
        "\n",
        "# Build augmented labels and train\n",
        "aug_label_train = np.asarray(list(itertools.chain.from_iterable([[label] * 2 for label in label_train])))\n",
        "AUG_MEL_SPECT_train = np.asarray(list(itertools.chain.from_iterable(AUG_MEL_SPECT_train)))\n",
        "\n",
        "# Concatenate original and augmented\n",
        "X_train = np.concatenate((MEL_SPECT_train, AUG_MEL_SPECT_train))\n",
        "y_train = np.concatenate((label_train, aug_label_train))\n",
        "\n",
        "# Build test set\n",
        "X_test = MEL_SPECT_test\n",
        "y_test = label_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EbACgpOJ4tRT"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nOrXhTXv4tRV"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CdeMK3Zz4tRX"
      },
      "source": [
        "win_ts = 128\n",
        "hop_ts = 64\n",
        "\n",
        "# Split spectrogram into frames\n",
        "def frame(x, win_step=128, win_size=64):\n",
        "    nb_frames = 1 + int((x.shape[2] - win_size) / win_step)\n",
        "    frames = np.zeros((x.shape[0], nb_frames, x.shape[1], win_size)).astype(np.float32)\n",
        "    for t in range(nb_frames):\n",
        "        frames[:,t,:,:] = np.copy(x[:,:,(t * win_step):(t * win_step + win_size)]).astype(np.float32)\n",
        "    return frames\n",
        "\n",
        "# Frame for TimeDistributed model\n",
        "X_train = frame(X_train, hop_ts, win_ts)\n",
        "X_test = frame(X_test, hop_ts, win_ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J-Y5FvON4tRZ"
      },
      "source": [
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(np.ravel(y_train)))\n",
        "y_test = np_utils.to_categorical(lb.transform(np.ravel(y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_YQ3awWR4tRd"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] , X_train.shape[2], X_train.shape[3], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] , X_test.shape[2], X_test.shape[3], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KFTSQLS94tRg"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Define two sets of inputs: MFCC and FBANK\n",
        "input_y = Input(shape=X_train.shape[1:], name='Input_MELSPECT')\n",
        "\n",
        "## First LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_1_MELSPECT')(input_y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_1_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_1_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'), name='MaxPool_1_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_1_MELSPECT')(y)     \n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_2_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_2_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_2_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_2_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_2_MELSPECT')(y)\n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_3_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_3_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_3_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_3_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_3_MELSPECT')(y)\n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_4_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_4_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_4_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_4_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_4_MELSPECT')(y)  \n",
        "\n",
        "## Flat\n",
        "y = TimeDistributed(Flatten(), name='Flat_MELSPECT')(y)                      \n",
        "                               \n",
        "# Apply 2 LSTM layer and one FC\n",
        "y = LSTM(256, return_sequences=False, dropout=0.2, name='LSTM_1')(y)\n",
        "y = Dense(y_train.shape[1], activation='softmax', name='FC')(y)\n",
        "\n",
        "# Build final model\n",
        "model = Model(inputs=input_y, outputs=y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvQKQnfAp3fa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3-3Vaj9p3YQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PuP1yQJ_4tRi"
      },
      "source": [
        "model.compile(optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.8), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=30, verbose=1, mode='max')\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(X_train, y_train, batch_size=84, epochs=200, validation_data=(X_test, y_test), callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qQqelkGS4tRk"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0JZ3vJLC4tRm"
      },
      "source": [
        "model.save('[CNN-LSTM]M.h5')\n",
        "model.save_weights('[CNN-LSTM]W.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "biktmIQ94tRo"
      },
      "source": [
        "model_name = 'Emotion_ModelLSTM.h5'\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Save model and weights at %s ' % model_path)\n",
        "\n",
        "# Save the model to disk\n",
        "model_json = model.to_json()\n",
        "with open(\"model_json.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TicTq-Vd4tRq"
      },
      "source": [
        "preds = model.predict(X_test)\n",
        "\n",
        "preds=preds.argmax(axis=1)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBj3nTGkrPYx"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "\n",
        "#y_pred_labels = np.argmax(preds, axis=1)  # only necessary if output has one-hot-encoding, shape=(n_samples)\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(y_true=y_test, y_pred=preds)  # shape=(12, 12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9_CsJzsy4tRt"
      },
      "source": [
        "path_ = '/content/drive/My Drive/audio_speech_actors_01-24/Actor_01/03-01-07-02-01-01-01.wav'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "knoZK9oj4tRw"
      },
      "source": [
        "import IPython.display as ipd\n",
        "ipd.Audio(path_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UbI1VNyb4tRy"
      },
      "source": [
        "s = []\n",
        "\n",
        "# Sample rate (16.0 kHz)\n",
        "sample_rate = 16000     \n",
        "\n",
        "# Max pad lenght (3.0 sec)\n",
        "max_pad_len = 49100\n",
        "\n",
        "X, sample_rate = librosa.load(path_,duration=3,offset=0.5)\n",
        "sample_rate = np.array(sample_rate)\n",
        "\n",
        "y = zscore(X)\n",
        "    \n",
        "# Padding or truncated signal \n",
        "if len(y) < max_pad_len:    \n",
        "    y_padded = np.zeros(max_pad_len)\n",
        "    y_padded[:len(y)] = y\n",
        "    y = y_padded\n",
        "elif len(y) > max_pad_len:\n",
        "    y = np.asarray(y[:max_pad_len])\n",
        "\n",
        "# Add to signal list\n",
        "s.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Do6wNd0G4tR0"
      },
      "source": [
        "mel_spect = np.asarray(list(map(mel_spectrogram, s)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "D7EWEIaD4tR2"
      },
      "source": [
        "win_ts = 128\n",
        "hop_ts = 64\n",
        "\n",
        "# Split spectrogram into frames\n",
        "def frame(x, win_step=128, win_size=64):\n",
        "    nb_frames = 1 + int((x.shape[2] - win_size) / win_step)\n",
        "    frames = np.zeros((x.shape[0], nb_frames, x.shape[1], win_size)).astype(np.float32)\n",
        "    for t in range(nb_frames):\n",
        "        frames[:,t,:,:] = np.copy(x[:,:,(t * win_step):(t * win_step + win_size)]).astype(np.float32)\n",
        "    return frames\n",
        "\n",
        "# Frame for TimeDistributed model\n",
        "x = frame(mel_spect, hop_ts, win_ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b2fCEpus4tR5"
      },
      "source": [
        "x = x.reshape(x.shape[0], x.shape[1] , x.shape[2], x.shape[3], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xNzwkZSl4tR7"
      },
      "source": [
        "preds = model.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2QfJnBdV4tR9"
      },
      "source": [
        "preds=preds.argmax(axis=1)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UK9qM_6p5Kx"
      },
      "source": [
        "\n",
        "    \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q-B1qgpp5W5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8zQ30WUqXqm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}